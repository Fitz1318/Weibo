Python3环境下使用scrapy爬取新浪微博用户信息和微博信息，并存储到MongoDB中。

2018/4/11更新，修改了部分代码，现在能够在爬取2W左右就被封IP了，
最关键的是内容爬取不完整！！！

--------------------*******************---------------------

2018/4/17更新：
①解决uid异常抛错处理
②针对爬虫过程中出现的个例403错误进行retry设置
③在pipelines中解决之前对于“昨天发表的微博的时间标准化问题“
  之前对于昨天发表的微博的时间一直不正确
④使用Github上的fake_useragent，替代之前少量的User-Agent
⑤增加了代码说明，方便阅读
⑥设置DOWNLOAD_DELAY = 0.5时是不会封号的，但是效率差点